{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)\tHow decision tree works for a regression problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The node which gives minimum MSE will be selected as parent node and splitting will be done.Now the feature which is selected \n",
    "as parent node will perform splitting on the basis of all possible values paresent for that feature.MSE is calculated on the partitioned dataset and output is given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)\tWhy Recursive binary splitting is called Greedy Approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While building Decision tree,to get the parent node or any node it tries to check all features available in dataset and which ever feature is giving max infogain is selected for further splitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)\tWhat do you understand by Greedy approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It greedily searches for an optimum split at the top level, then repeats the process at each level. It does not check whether or not the split will lead to the lowest possible impurity several levels down. A greedy algorithm often produces a reasonably good solution, but it is not guaranteed to be the optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4)\tWhat is Pruning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree obtained from recurive binary splitting is based on all features and has large depth.Some time it happens at leaf node we are left with minimum datapoints which may lead to overfitting.To overcome this problem tree pruning is done where branches of tree whcih is not so important are cut down with the help of cross validation.\n",
    "Pruning is regularization technique of decision tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5)\tWhat’s the difference between pre pruning and post pruning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pre pruning the non segnificant branches are not allowed to grow and in post pruning first the whole tree is grwon and then \n",
    "non significant splits are cut out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6)\tWhat is Entropy? How is it calculated?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy is the randomness in the dataset i.e how many types of datapoints are available(wrt categories)\n",
    "\n",
    "E = -p*log2(p)\n",
    "\n",
    "where p =probability of  class I when a feature is selected (classification) with respect to 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7)\tWhat is Gini Impurity?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini impurity is a measure of how often a randomly chosen element from the set would be incorrectly labelled if it was randomly labelled according to the distribution of labels in the subset.’ It is calculated by multiplying the probability that a given observation is classified into the correct class and sum of all the probabilities when that particular observation is classified into the wrong class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8)\tWhat do you understand by Information Gain? How does it help in tree building?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information gain refers to difference of parent node entropy and weighted average entropy after splitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9)\tHow does node selection take place while building a tree?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature which gives high IG, will be used to select the node to build a tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10)\tWhat are different algorithms available for decision tree?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)ID3\n",
    "2)C4.5\n",
    "3)Classification And Regression Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11)\tWhat’s the main difference between Gini Impurity and Entropy on the basis of computation time?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy involves calculation of log where as gini impurity is simply multiplication of probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12)\tWhat are the disadvantages and advantages of using a Decision Tree?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantage of DT\n",
    "1)Highly interpetable.\n",
    "2)Easy to understand.\n",
    "3)Standardization and Normalization is not required.\n",
    "\n",
    "Disadvantage of DT\n",
    "1)Training time is quite high as it tries to look for all features however this has been overcome by tuning hyperparameter max_feature.\n",
    "2)DT doesnot give good results on large dimensionand small datapoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13)\tHow do you deploy model in Heroku?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)After installing the Heroku CLI, Open a command prompt window and navigate to your project folder.\n",
    "2)Type the command heroku login to login to your heroku account.\n",
    "3)After logging in to Heroku, enter the command heroku create to create a heroku app. It will give you the URL of your Heroku app after successful creation. Or alternatively, you can go to the heroku website and create an app directly.\n",
    "4)Before deploying the code to the Heroku cloud, we need to commit the changes to the git repository.\n",
    "5)Type the command git init to initialize a local git repository.\n",
    "6)Enter the command git status to see the uncommitted changes.\n",
    "7)Enter the command git add . to add the uncommitted changes to the local repository.\n",
    "8)Enter the command git commit -am \"make it better\" to commit the changes to the local repository.\n",
    "9)Enter the command git push heroku master to push the code to the heroku cloud.\n",
    "10)After deployment, heroku gives you the URL to hit the web API.\n",
    "11)Once your application is deployed successfully, enter the command heroku logs --tail to see the logs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14)\tWhat challenges you faced while deploying the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)\tWhat is Cross validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation is resampling technique where whole dataset is divided into training set and testing set.Model is built on training set and model performance is evalutaed on test data which is not seen by model during training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)\tWhy do we need to implement Cross validation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO avoid overfitting problem we need to implement cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)\tWhat are different types of CV methods?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)Hold Out Method\n",
    "2)k-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4)\tHow bias and variance varies for each CV method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)Hold Out Method:-Low Bias and High variance\n",
    "2)k-fold Cross-Validation:-Low Bias and possibility of High variance\n",
    "3)Leave One Out Cross Validation:-Low Bias and relatively low variance compared to K-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "5)\tIs Train Test Split a kind of CV? True or False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "6)\tHow can we check over fitting using CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "If the training score is 1 than it is case of overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
